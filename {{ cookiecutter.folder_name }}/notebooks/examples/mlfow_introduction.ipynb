{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1405501-a54f-4b11-96e6-215ac61f616a",
   "metadata": {},
   "source": [
    "# Introduction to MLflow APIs for Experiment Tracking\n",
    "\n",
    "MLflow is an open‐source platform designed to manage the end-to-end machine learning lifecycle. In this section, we introduce several key MLflow APIs that you can use to set up your experiment tracking, log runs and models, and manage your model registry. For more details, refer to the official [MLflow documentation](mlflow.org)\n",
    "\n",
    "\n",
    "This notebook provides a starting point on how to use MLFLow for logging your experiements and artifacts.\n",
    "\n",
    "Before starting this notebook, make sure the services are running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad4a766-48a2-49ca-96b4-98b55ebdb1fe",
   "metadata": {},
   "source": [
    "## Setting Up the Tracking Environment\n",
    "\n",
    "Before you begin logging experiments and models, you must configure the tracking server. MLflow uses a tracking URI to know where to store experiment data such as metrics, parameters, and artifacts.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.set_tracking_uri(uri)\n",
    "\n",
    "    What it does: Configures the tracking server’s URI (this can be a local directory, a remote HTTP endpoint, or a database URI).\n",
    "    When to use: Call this at the very start of your script to ensure all logs go to the correct destination.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.get_tracking_uri()\n",
    "\n",
    "    What it does: Retrieves the currently configured tracking URI, which is useful for debugging or verifying your setup.\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a8776-1f44-485f-b664-a94f6831d65b",
   "metadata": {},
   "source": [
    "## Managing Experiments\n",
    "\n",
    "Experiments group related runs, making it easier to organize and compare different model training sessions.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.create_experiment(experiment_name)\n",
    "\n",
    "    What it does: Explicitly creates a new experiment and returns its unique ID.\n",
    "    When to use: When you want to programmatically create an experiment without necessarily switching to it immediately.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    What it does: Sets the active experiment for your run. If the experiment doesn’t already exist, it will be created automatically.\n",
    "    When to use: At the beginning of your experiment code to ensure all subsequent runs are recorded under the correct experiment.\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70990c0-27ad-4644-99c9-d1ce995e8a43",
   "metadata": {},
   "source": [
    "## Logging Runs and Enabling Auto-Logging\n",
    "\n",
    "Once your tracking environment and experiment are set, you can start logging runs.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.start_run()\n",
    "\n",
    "    What it does: Starts a new MLflow run and returns an ActiveRun object. It can be used as a context manager so that the run is automatically ended when the block finishes.\n",
    "    When to use: Wrap your training (or any experimental) code within a with mlflow.start_run(): block to log parameters, metrics, and artifacts.\n",
    "    Note: You can use one start_run inside another which forms a parent-child relationship between them leading to grouped experiments by setting `nested=True` inside the start_run of the child (useful for hyperparameter-tuning)\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.log_params(params_dict)\n",
    "\n",
    "    Log multiple parameters at once by passing a dictionary. Example:\n",
    "\n",
    "    params = {\"learning_rate\": 0.01, \"num_layers\": 3, \"batch_size\": 32}\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.log_param(key, value)\n",
    "\n",
    "    Log a single parameter. Parameters are typically hyperparameters or configuration values. Example:\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_param(key=\"data_source\", value=s3_path)\n",
    "\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.log_figure(figure, artifact_file)\n",
    "\n",
    "    What it does: Logs a matplotlib figure or plotly figure as an artifact file (e.g., a PNG image).\n",
    "    When to use: Use this after generating plots (e.g., loss curves, confusion matrices) to store them alongside the run. Example:\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot([0, 1], [0, 1])\n",
    "    mlflow.log_figure(fig, \"plots/line_plot.png\")\n",
    "\n",
    "======================================================\n",
    "\n",
    "\n",
    "    mlflow.autolog()\n",
    "\n",
    "    What it does: Automatically logs parameters, metrics, and models from supported machine learning libraries (such as scikit-learn, TensorFlow, PyTorch, etc.).\n",
    "    When to use: Use this at the beginning of your training code to minimize manual logging.\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.<framework>.log_model()\n",
    "\n",
    "    What it does: Logs a trained model as an artifact. Replace <framework> with the specific module (e.g., sklearn, tensorflow, or pytorch).\n",
    "    When to use: After you’ve trained your model, call this function to save the model so that it can later be served or compared.\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0e13c3-8a4e-462e-9f53-ebe58059f647",
   "metadata": {},
   "source": [
    "## Loading Models\n",
    "\n",
    "======================================================\n",
    "\n",
    "    mlflow.pyfunc.load_model()\n",
    "\n",
    "    What it does: Loads a model from a specified URI in a uniform “pyfunc” format that works for inference.\n",
    "    When to use: When you need to load a logged model for making predictions.\n",
    "\n",
    "======================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fbfa0a-0eba-4472-b306-1afb80917ae8",
   "metadata": {},
   "source": [
    "## Custom Python Model\n",
    "\n",
    "======================================================\n",
    "\n",
    "\n",
    "What is it: Most of the times, we require certain preprocessing and/or postprocessing before/after the prediction of the model. The model that mlflow creates for us by default only contains the model itself. If you need to add some pre/postprocessing steps, you can use custom python model to create model pipelines. Please see this link to learn more: https://mlflow.org/docs/latest/traditional-ml/creating-custom-pyfunc/index.html\n",
    "\n",
    "\n",
    "======================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d50a657-fce7-4768-a86b-8243370d15c0",
   "metadata": {},
   "source": [
    "Below we apply the concepts above to an example ML project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350435f4-6f17-4a62-8c3f-11b9e0d08e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "\n",
    "import boto3\n",
    "import mlflow\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import tensorflow.keras as keras\n",
    "from botocore.exceptions import ClientError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ed963e-28d3-48c9-b545-b7062dc13469",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4779e97-3d94-44be-a70a-b51e5fa26213",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"MLFLOW_S3_ENDPOINT_URL\"] = os.getenv(\"J_MLFLOW_S3_ENDPOINT_URL\")\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = os.getenv(\"J_MLFLOW_TRACKING_URI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a6fd82-0246-466d-b20f-9d76751bdb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=os.getenv(\"J_MLFLOW_S3_ENDPOINT_URL\"),\n",
    "    aws_access_key_id=os.getenv(\"AWS_ACCESS_KEY_ID\"),\n",
    "    aws_secret_access_key=os.getenv(\"AWS_SECRET_ACCESS_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad33add-5079-4800-ad35-8dad3a29e708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_experiment(experiment_name):\n",
    "    \"\"\"\n",
    "    Retrieve the ID of an existing MLflow experiment or create a new one if it doesn't exist.\n",
    "\n",
    "    This function checks if an experiment with the given name exists within MLflow.\n",
    "    If it does, the function returns its ID. If not, it creates a new experiment\n",
    "    with the provided name and returns its ID.\n",
    "\n",
    "    Taken from mlflow.org\n",
    "\n",
    "    Parameters:\n",
    "    - experiment_name (str): Name of the MLflow experiment.\n",
    "\n",
    "    Returns:\n",
    "    - str: ID of the existing or newly created MLflow experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    if experiment := mlflow.get_experiment_by_name(experiment_name):\n",
    "        return experiment.experiment_id\n",
    "    else:\n",
    "        return mlflow.create_experiment(experiment_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5dc76c-83eb-45f6-8201-c1e75f486059",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_data_path(\n",
    "        s3_client: boto3.client,\n",
    "        bucket_name: str,\n",
    "        base_folder: str = 'preprocessing'\n",
    ") -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Find the latest timestamp folder and NPZ file in the specified bucket/folder\n",
    "    Returns tuple of (full_path, filename)\n",
    "    \"\"\"\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=f\"{base_folder}/\",\n",
    "        Delimiter='/'\n",
    "    )\n",
    "\n",
    "    timestamps = []\n",
    "    for prefix in response.get('CommonPrefixes', []):\n",
    "        folder_name = prefix['Prefix'].strip('/')\n",
    "        try:\n",
    "            timestamp = folder_name.replace(f\"{base_folder}/\", '')\n",
    "            timestamps.append(timestamp)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    if not timestamps:\n",
    "        raise ValueError(\"No timestamp folders found\")\n",
    "\n",
    "    latest_timestamp = sorted(timestamps)[-1]\n",
    "    latest_folder = f\"{base_folder}/{latest_timestamp}\"\n",
    "\n",
    "    response = s3_client.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=latest_folder\n",
    "    )\n",
    "\n",
    "    npz_files = [\n",
    "        obj['Key'] for obj in response.get('Contents', [])\n",
    "        if obj['Key'].endswith('.npz')\n",
    "    ]\n",
    "\n",
    "    if not npz_files:\n",
    "        raise ValueError(f\"No NPZ files found in {latest_folder}\")\n",
    "\n",
    "    latest_file = npz_files[0]\n",
    "    return latest_file, latest_file.split('/')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22f2f8-268f-4725-b84c-dd17713313f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_store():\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "    (X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "    X_train = X_train.astype('float32') / 255.0\n",
    "    X_test = X_test.astype('float32') / 255.0\n",
    "    X_train = np.expand_dims(X_train, axis=-1)\n",
    "    X_test = np.expand_dims(X_test, axis=-1)\n",
    "\n",
    "    local_path = f\"/tmp/mnist_processed_{timestamp}.npz\"\n",
    "    np.savez_compressed(local_path,\n",
    "                        X_train=X_train, y_train=y_train,\n",
    "                        X_test=X_test, y_test=y_test)\n",
    "\n",
    "    bucket_name = \"mnist-data\"\n",
    "    object_path = f\"preprocessing/{timestamp}/mnist_processed.npz\"\n",
    "\n",
    "    try:\n",
    "        s3.head_bucket(Bucket=bucket_name)\n",
    "    except ClientError:\n",
    "        print(f\"Bucket: {bucket_name} does not exist, creating one now!\")\n",
    "        s3.create_bucket(Bucket=bucket_name)\n",
    "\n",
    "    s3.upload_file(local_path, bucket_name, object_path)\n",
    "\n",
    "    os.remove(local_path)\n",
    "    print(f\"Preprocessed data stored to MinIO: {object_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adc638e-7ad5-4774-99db-482213c59af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist():\n",
    "\n",
    "    bucket_name=\"mnist-data\"\n",
    "    base_folder=\"preprocessing\"\n",
    "    s3_path, filename = get_latest_data_path(s3, bucket_name=bucket_name,\n",
    "                                             base_folder=base_folder)\n",
    "    local_path = \"/tmp\"\n",
    "    local_file = f\"{local_path}/{filename}\"\n",
    "    s3.download_file(bucket_name, s3_path, local_file)\n",
    "\n",
    "    data = np.load(local_file)\n",
    "    X_train, y_train = data['X_train'], data['y_train']\n",
    "    X_test, y_test = data['X_test'], data['y_test']\n",
    "\n",
    "    y_train = keras.utils.to_categorical(y_train, 10)\n",
    "    y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    mlflow.set_tracking_uri(os.getenv(\"J_MLFLOW_TRACKING_URI\"))\n",
    "    experiment_id=get_or_create_experiment(\"MNIST_Hyperparameter_Search_autolog\")\n",
    "    mlflow.set_experiment(experiment_id=experiment_id)\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_model = None\n",
    "    best_params = {}\n",
    "\n",
    "    HYPERPARAM_GRID = {\n",
    "        'epochs': [1, 2]\n",
    "    }\n",
    "\n",
    "    keys, values = zip(*HYPERPARAM_GRID.items())\n",
    "    param_combinations = [dict(zip(keys, v)) for v in\n",
    "                          itertools.product(*values)]\n",
    "\n",
    "    mlflow.autolog()\n",
    "    with mlflow.start_run(run_name=\"mnist-hyperparameter-tuning-parent\"):\n",
    "        for params in param_combinations:\n",
    "            with mlflow.start_run(nested=True):\n",
    "                model = keras.Sequential([\n",
    "                    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "                    keras.layers.MaxPooling2D((2, 2)),\n",
    "                    keras.layers.Flatten(),\n",
    "                    keras.layers.Dense(128, activation='relu'),\n",
    "                    keras.layers.Dense(10, activation='softmax')\n",
    "                ])\n",
    "\n",
    "                optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "                model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "                history = model.fit(\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    epochs=params['epochs'],\n",
    "                    validation_data=(X_test, y_test),\n",
    "                )\n",
    "\n",
    "                val_acc = history.history['val_accuracy'][-1]\n",
    "\n",
    "                if val_acc > best_accuracy:\n",
    "                    best_accuracy = val_acc\n",
    "                    best_model = model\n",
    "                    best_params = params\n",
    "\n",
    "            if best_model is not None:\n",
    "                artifact_path = \"mnist_model_autolog\"\n",
    "                mlflow.tensorflow.log_model(model, artifact_path)\n",
    "\n",
    "                model_uri = mlflow.get_artifact_uri(artifact_path)\n",
    "                print(\"Model stored at \", model_uri)\n",
    "                print(\"Best Params \", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9ef840-facd-432a-9ca6-92756fa03929",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_and_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2c5991-6c3d-4649-833c-91289db9e983",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_mnist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
